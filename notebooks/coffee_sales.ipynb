{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20402fa2",
   "metadata": {},
   "source": [
    "# Brewed Insights: Coffee Sales Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f8f0fd",
   "metadata": {},
   "source": [
    "### 1. Install and import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca105b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07125169",
   "metadata": {},
   "source": [
    "### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data into a Pandas DataFrame\n",
    "base_path = os.path.dirname(os.getcwd())  # go up from notebooks folder\n",
    "data_path = os.path.join(base_path, 'data', 'coffee_sales.csv')\n",
    "\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4121c",
   "metadata": {},
   "source": [
    "### 3. Handle Cross-Year Data (Mar 2024 - Mar 2025)\n",
    "- Handling the non-standard fiscal year and a single continuous time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae57bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the Date and Time columns\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "# Handle inconsistent time formats (some have milliseconds, some don't)\n",
    "df['DateTime'] = pd.to_datetime(df['Date'].astype(str) + ' ' + df['Time'].astype(str), format='mixed') # mixed format parsing\n",
    "\n",
    "# Extract Year for calculations\n",
    "df['Year'] = df['Date'].dt.year\n",
    "\n",
    "# Create sequential month number (handles cross-year properly)\n",
    "# This counts unique year-month combinations\n",
    "df['month_sequence'] = (\n",
    "    (df['Date'].dt.year - df['Date'].dt.year.min()) * 12 + \n",
    "    df['Date'].dt.month\n",
    ")\n",
    "# Normalize to start from 1\n",
    "df['month_sequence'] = df['month_sequence'] - df['month_sequence'].min() + 1\n",
    "\n",
    "# Create display labels for months (e.g., \"Mar 2024\", \"Apr 2024\")\n",
    "df['year_month_display'] = df['Date'].dt.strftime('%b %Y')\n",
    "\n",
    "# Create year_month_sort for proper ordering\n",
    "df['year_month_sort'] = df['Date'].dt.year * 100 + df['Date'].dt.month\n",
    "\n",
    "# Create fiscal year fields (March = Month 1)\n",
    "FISCAL_START_MONTH = 3  # March\n",
    "df['fiscal_month'] = ((df['Date'].dt.month - FISCAL_START_MONTH) % 12) + 1 # Fiscal month 1 = March\n",
    "df['fiscal_year'] = df['Date'].dt.year # Initial fiscal year\n",
    "df.loc[df['Date'].dt.month < FISCAL_START_MONTH, 'fiscal_year'] -= 1 # Adjust fiscal year for Jan/Feb\n",
    "\n",
    "# Create fiscal period label for display\n",
    "df['fiscal_period'] = 'FY' + df['fiscal_year'].astype(str) + '-M' + df['fiscal_month'].astype(str).str.zfill(2)\n",
    "\n",
    "print(\"âœ“ Cross-year data handling complete\")\n",
    "print(f\"Data spans: {df['year_month_display'].min()} to {df['year_month_display'].max()}\")\n",
    "print(f\"Total unique months: {df['month_sequence'].nunique()}\")\n",
    "print(f\"Date range: {df['Date'].min().date()} to {df['Date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9168da00",
   "metadata": {},
   "source": [
    "### 4. Create a temporary database using SQLite and insert the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f896d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary SQLite database\n",
    "conn = sqlite3.connect('coffee.db')\n",
    "\n",
    "# Write the DataFrame into a SQL table\n",
    "df.to_sql('coffee_sales', conn, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af24608",
   "metadata": {},
   "source": [
    "### 5. Create a function that will be reutilized later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56172bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query, conn):\n",
    "    \"\"\"Helper function to run SQL queries and return DataFrame.\"\"\"\n",
    "    return pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f78b5",
   "metadata": {},
   "source": [
    "### 6. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae780cf",
   "metadata": {},
   "source": [
    "#### 6.1 Top-Selling Coffee Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93adecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sellers = run_query(\"\"\"\n",
    "SELECT coffee_name, \n",
    "       COUNT(*) AS total_sales, \n",
    "       ROUND(SUM(money), 2) AS total_revenue,\n",
    "       ROUND(AVG(money), 2) AS avg_price\n",
    "FROM coffee_sales\n",
    "GROUP BY coffee_name\n",
    "ORDER BY total_revenue DESC\n",
    "LIMIT 10;\n",
    "\"\"\", conn)\n",
    "\n",
    "print(top_sellers.to_string(index=False)) # to_string to avoid truncation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab496bc0",
   "metadata": {},
   "source": [
    "#### 6.2 Peak Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc761da",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_hours = run_query(\"\"\"\n",
    "SELECT hour_of_day, \n",
    "       ROUND(SUM(money), 2) AS total_revenue,\n",
    "       COUNT(*) AS transactions\n",
    "FROM coffee_sales\n",
    "GROUP BY hour_of_day\n",
    "ORDER BY hour_of_day;\n",
    "\"\"\", conn)\n",
    "\n",
    "print(peak_hours.to_string(index=False))\n",
    "print(f\"\\nPeak Hour: {peak_hours.loc[peak_hours['total_revenue'].idxmax(), 'hour_of_day']}:00\")\n",
    "print(f\"Peak Revenue: ${peak_hours['total_revenue'].max():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5e48cd",
   "metadata": {},
   "source": [
    "#### 6.3 Revenue by Day of the Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63801df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_by_day = run_query(\"\"\"\n",
    "SELECT Weekday, \n",
    "       ROUND(SUM(money), 2) AS total_revenue,\n",
    "       COUNT(*) AS transactions,\n",
    "       ROUND(AVG(money), 2) AS avg_transaction\n",
    "FROM coffee_sales\n",
    "GROUP BY Weekday\n",
    "ORDER BY Weekdaysort;\n",
    "\"\"\", conn)\n",
    "\n",
    "print(revenue_by_day.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cce2e7",
   "metadata": {},
   "source": [
    "#### 6.4 Average Sale per Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sale_hour = run_query(\"\"\"\n",
    "SELECT hour_of_day,\n",
    "       ROUND(AVG(money), 2) AS avg_sale_per_hour,\n",
    "       COUNT(*) AS transactions\n",
    "FROM coffee_sales\n",
    "GROUP BY hour_of_day\n",
    "ORDER BY hour_of_day;\n",
    "\"\"\", conn)\n",
    "\n",
    "print(avg_sale_hour.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a92a8",
   "metadata": {},
   "source": [
    "#### 6.5 Monthly Sales Performance: Growth Rate by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82741bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use month_sequence for proper ordering\n",
    "monthly_sales = df.groupby(['year_month_display', 'month_sequence', 'year_month_sort'])['money'].agg([\n",
    "    ('total_revenue', 'sum'),\n",
    "    ('transactions', 'count'),\n",
    "    ('avg_transaction', 'mean')\n",
    "]).reset_index()\n",
    "monthly_sales = monthly_sales.sort_values('month_sequence')\n",
    "\n",
    "# Calculate growth rate\n",
    "monthly_sales['growth_rate'] = (\n",
    "    monthly_sales['total_revenue'].pct_change().fillna(0) * 100\n",
    ").round(2)\n",
    "\n",
    "# Display with proper labels\n",
    "monthly_display = monthly_sales[['year_month_display', 'total_revenue', 'transactions', 'growth_rate']].copy()\n",
    "monthly_display['total_revenue'] = monthly_display['total_revenue'].apply(lambda x: f\"${x:,.2f}\")\n",
    "monthly_display['growth_rate'] = monthly_display['growth_rate'].apply(lambda x: f\"{x:.2f}%\")\n",
    "monthly_display.columns = ['Period', 'Revenue', 'Transactions', 'Growth Rate']\n",
    "print(monthly_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b064943e",
   "metadata": {},
   "source": [
    "#### 6.6 Sales by Time of Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3bc927",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_of_day_analysis = run_query(\"\"\"\n",
    "SELECT Time_of_Day,\n",
    "       COUNT(*) AS transactions,\n",
    "       ROUND(SUM(money), 2) AS total_revenue,\n",
    "       ROUND(AVG(money), 2) AS avg_transaction\n",
    "FROM coffee_sales\n",
    "GROUP BY Time_of_Day\n",
    "ORDER BY \n",
    "    CASE Time_of_Day\n",
    "        WHEN 'Morning' THEN 1\n",
    "        WHEN 'Afternoon' THEN 2\n",
    "        WHEN 'Night' THEN 3\n",
    "    END;\n",
    "\"\"\", conn)\n",
    "\n",
    "print(time_of_day_analysis.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01345b08",
   "metadata": {},
   "source": [
    "### 7. Outliers: Extreme Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e2f28d",
   "metadata": {},
   "source": [
    "#### 7.1 Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for top 25% transactions\n",
    "threshold = df['money'].quantile(0.75)\n",
    "high_value_sales = df[df['money'] >= threshold]\n",
    "\n",
    "# Summary statistics for high-value transactions\n",
    "num_outliers = len(high_value_sales)\n",
    "total_outliers = high_value_sales['money'].sum()\n",
    "avg_outliers = high_value_sales['money'].mean()\n",
    "pct_of_total = total_outliers / df['money'].sum() * 100\n",
    "\n",
    "# Display summary\n",
    "summary = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"High-value transactions\", \n",
    "        \"Total revenue\", \n",
    "        \"Average value\", \n",
    "        \"% of total revenue\",\n",
    "        \"Threshold value\"\n",
    "    ], \n",
    "    \"Value\": [\n",
    "        f\"{num_outliers:,}\",\n",
    "        f\"${total_outliers:,.2f}\", \n",
    "        f\"${avg_outliers:.2f}\", \n",
    "        f\"{pct_of_total:.2f}%\",\n",
    "        f\"${threshold:.2f}\"\n",
    "    ]\n",
    "})\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87753fba",
   "metadata": {},
   "source": [
    "#### 7.2 High-Value Coffee Transactions: Item Contribution to Top Sales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate high-value sales by coffee item\n",
    "coffee_high_value = high_value_sales.groupby('coffee_name').agg(\n",
    "    total_revenue=('money', 'sum'), # total revenue from high-value sales\n",
    "    transaction_count=('money', 'count'), # number of high-value transactions\n",
    "    avg_value=('money', 'mean') # average value of high-value transactions\n",
    ").sort_values(by='total_revenue', ascending=False)\n",
    "\n",
    "# Calculate percentage of high-value revenue for each coffee item\n",
    "coffee_high_value['pct_of_high_value_revenue'] = (\n",
    "    coffee_high_value['total_revenue'] / high_value_sales['money'].sum() * 100\n",
    ").round(2)\n",
    "\n",
    "# Format monetary values and percentages for display\n",
    "coffee_high_value['total_revenue'] = coffee_high_value['total_revenue'].apply(lambda x: f\"${x:,.2f}\")\n",
    "coffee_high_value['avg_value'] = coffee_high_value['avg_value'].apply(lambda x: f\"${x:.2f}\")\n",
    "coffee_high_value['pct_of_high_value_revenue'] = coffee_high_value['pct_of_high_value_revenue'].apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "print(coffee_high_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6e3d3",
   "metadata": {},
   "source": [
    "### 8. Predictive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13480053",
   "metadata": {},
   "source": [
    "#### 8.1 Hourly Sales Forecast (6:00 - 22:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10febb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate average sales by hour\n",
    "hourly_sales = df.groupby('hour_of_day')['money'].mean().reset_index()\n",
    "X = hourly_sales[['hour_of_day']]\n",
    "y = hourly_sales['money']\n",
    "\n",
    "# Polynomial regression model (degree 2), for capturing peak/off-peak trends\n",
    "poly_hour_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "poly_hour_model.fit(X, y)\n",
    "\n",
    "# Predict average sales for each hour from 6:00 to 22:00\n",
    "future_hours = pd.DataFrame({'hour_of_day': range(6, 23)})\n",
    "predicted_hourly_sales = poly_hour_model.predict(future_hours)\n",
    "\n",
    "# Format and display predictions\n",
    "predicted_hourly_sales_df = future_hours.copy()\n",
    "predicted_hourly_sales_df['predicted_avg_transaction'] = predicted_hourly_sales\n",
    "predicted_hourly_sales_df['predicted_avg_transaction'] = predicted_hourly_sales_df['predicted_avg_transaction'].apply(\n",
    "    lambda x: f\"${x:.2f}\"\n",
    ")\n",
    "predicted_hourly_sales_df['hour'] = predicted_hourly_sales_df['hour_of_day'].apply(lambda x: f\"{x}:00\")\n",
    "print(predicted_hourly_sales_df[['hour', 'predicted_avg_transaction']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b14649",
   "metadata": {},
   "source": [
    "#### 8.2 Monthly Sales Forecast (Next 3 Months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb207168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use month_sequence for proper temporal ordering\n",
    "monthly_sales_seq = df.groupby('month_sequence')['money'].sum().reset_index()\n",
    "monthly_sales_seq = monthly_sales_seq.sort_values('month_sequence')\n",
    "\n",
    "# Polynomial regression model (degree 2) for monthly sales trend, capturing non-linear growth\n",
    "X_month = monthly_sales_seq[['month_sequence']]\n",
    "y_month = monthly_sales_seq['money']\n",
    "\n",
    "poly_month_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "poly_month_model.fit(X_month, y_month)\n",
    "\n",
    "# Predict next 3 months after the last month in your data\n",
    "max_month = df['month_sequence'].max()\n",
    "future_months = pd.DataFrame({'month_sequence': [max_month + 1, max_month + 2, max_month + 3]})\n",
    "predicted_monthly_sales = poly_month_model.predict(future_months)\n",
    "\n",
    "# Create readable labels based on your last date\n",
    "last_date = df['Date'].max()\n",
    "future_dates = pd.date_range(start=last_date + pd.DateOffset(months=1), periods=3, freq='MS')\n",
    "\n",
    "# Format and display predictions\n",
    "predicted_monthly_sales_df = pd.DataFrame({\n",
    "    'Period': future_dates.strftime('%b %Y'),\n",
    "    'Predicted Revenue': [f\"${x:,.2f}\" for x in predicted_monthly_sales],\n",
    "    'Month Sequence': [max_month + 1, max_month + 2, max_month + 3]\n",
    "})\n",
    "print(predicted_monthly_sales_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d0373",
   "metadata": {},
   "source": [
    "### 9. Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26556280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get date range information\n",
    "first_month = df.loc[df['Date'].idxmin(), 'year_month_display']\n",
    "last_month = df.loc[df['Date'].idxmax(), 'year_month_display']\n",
    "\n",
    "# Calculate summary statistics\n",
    "total_revenue = df['money'].sum()\n",
    "total_transactions = len(df)\n",
    "avg_transaction = df['money'].mean()\n",
    "unique_products = df['coffee_name'].nunique()\n",
    "\n",
    "# Display summary\n",
    "print(f\"Analysis Period: {first_month} to {last_month}\")\n",
    "print(f\"Total Duration: {df['month_sequence'].nunique()} months\")\n",
    "print(f\"Date Range: {df['Date'].min().date()} to {df['Date'].max().date()}\")\n",
    "print(f\"\\nTotal Transactions: {total_transactions:,}\")\n",
    "print(f\"Total Revenue: ${total_revenue:,.2f}\")\n",
    "print(f\"Average Transaction: ${avg_transaction:.2f}\")\n",
    "print(f\"Unique Products: {unique_products}\")\n",
    "print(f\"\\nPeak Hour: {peak_hours.loc[peak_hours['total_revenue'].idxmax(), 'hour_of_day']}:00 (${peak_hours['total_revenue'].max():,.2f})\")\n",
    "print(f\"Best Day: {revenue_by_day.loc[revenue_by_day['total_revenue'].idxmax(), 'Weekday']} (${revenue_by_day['total_revenue'].max():,.2f})\")\n",
    "print(f\"Top Product: {top_sellers.iloc[0]['coffee_name']} (${top_sellers.iloc[0]['total_revenue']:,.2f} revenue)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce10935",
   "metadata": {},
   "source": [
    "### 10. Close the Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (biodiversity)",
   "language": "python",
   "name": "biodiversity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
