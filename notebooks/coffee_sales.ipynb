{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20402fa2",
   "metadata": {},
   "source": [
    "# Brewed Insights: Coffee Sales Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f8f0fd",
   "metadata": {},
   "source": [
    "### 1. Install and import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca105b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07125169",
   "metadata": {},
   "source": [
    "### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff8a1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data into a Pandas DataFrame\n",
    "base_path = os.path.dirname(os.getcwd())  # go up from notebooks folder\n",
    "data_path = os.path.join(base_path, 'data', 'coffee_sales.csv')\n",
    "\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4121c",
   "metadata": {},
   "source": [
    "### 3. Handle Cross-Year Data (Mar 2024 - Mar 2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae57bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cross-year data handling complete\n",
      "Data spans: Apr 2024 to Sep 2024\n",
      "Total unique months: 13\n",
      "Date range: 2024-03-01 to 2025-03-23\n"
     ]
    }
   ],
   "source": [
    "# Parse the Date and Time columns\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "# Handle inconsistent time formats (some have milliseconds, some don't)\n",
    "df['DateTime'] = pd.to_datetime(df['Date'].astype(str) + ' ' + df['Time'].astype(str), format='mixed') # mixed format parsing\n",
    "\n",
    "# Extract Year for calculations\n",
    "df['Year'] = df['Date'].dt.year\n",
    "\n",
    "# Create sequential month number (handles cross-year properly)\n",
    "# This counts unique year-month combinations\n",
    "df['month_sequence'] = (\n",
    "    (df['Date'].dt.year - df['Date'].dt.year.min()) * 12 + \n",
    "    df['Date'].dt.month\n",
    ")\n",
    "# Normalize to start from 1\n",
    "df['month_sequence'] = df['month_sequence'] - df['month_sequence'].min() + 1\n",
    "\n",
    "# Create display labels for months (e.g., \"Mar 2024\", \"Apr 2024\")\n",
    "df['year_month_display'] = df['Date'].dt.strftime('%b %Y')\n",
    "\n",
    "# Create year_month_sort for proper ordering\n",
    "df['year_month_sort'] = df['Date'].dt.year * 100 + df['Date'].dt.month\n",
    "\n",
    "# Create fiscal year fields (March = Month 1)\n",
    "FISCAL_START_MONTH = 3  # March\n",
    "df['fiscal_month'] = ((df['Date'].dt.month - FISCAL_START_MONTH) % 12) + 1 # Fiscal month 1 = March\n",
    "df['fiscal_year'] = df['Date'].dt.year # Initial fiscal year\n",
    "df.loc[df['Date'].dt.month < FISCAL_START_MONTH, 'fiscal_year'] -= 1 # Adjust fiscal year for Jan/Feb\n",
    "\n",
    "# Create fiscal period label for display\n",
    "df['fiscal_period'] = 'FY' + df['fiscal_year'].astype(str) + '-M' + df['fiscal_month'].astype(str).str.zfill(2)\n",
    "\n",
    "print(\"✓ Cross-year data handling complete\")\n",
    "print(f\"Data spans: {df['year_month_display'].min()} to {df['year_month_display'].max()}\")\n",
    "print(f\"Total unique months: {df['month_sequence'].nunique()}\")\n",
    "print(f\"Date range: {df['Date'].min().date()} to {df['Date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9168da00",
   "metadata": {},
   "source": [
    "### 4. Create a temporary database using SQLite and insert the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f896d8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3547"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a temporary SQLite database\n",
    "conn = sqlite3.connect('coffee.db')\n",
    "\n",
    "# Write the DataFrame into a SQL table\n",
    "df.to_sql('coffee_sales', conn, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af24608",
   "metadata": {},
   "source": [
    "### 5. Create a function that will be reutilized later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56172bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query, conn):\n",
    "    \"\"\"Helper function to run SQL queries and return DataFrame.\"\"\"\n",
    "    return pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f78b5",
   "metadata": {},
   "source": [
    "### 6. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae780cf",
   "metadata": {},
   "source": [
    "#### 6.1 Top-Selling Coffee Products\n",
    "\n",
    "The top 5 best-selling drinks (ordered by total revenue) are:\n",
    "\n",
    "1. **Latte** – 757 units sold, $26,875.30 revenue  \n",
    "2. **Americano with Milk** – 809 units sold, $24,751.12 revenue  \n",
    "3. **Capuccino** – 486 units sold, $17,439.14 revenue  \n",
    "4. **Americano** – 564 units sold, $14,650.26 revenue  \n",
    "5. **Cortado** – 287 units sold, $7,384.86 revenue\n",
    "\n",
    "**Strategy Recommendations:**\n",
    "- **Menu focus**: Promote top-performing drinks like Latte and Americano with Milk during peak hours to maximize revenue.\n",
    "- **Upselling opportunities**: Encourage add-ons or combos for mid-level sellers like Capuccino and Cortado to boost average ticket.\n",
    "- **Inventory planning**: Ensure adequate stock of high-demand drinks, especially during morning and afternoon peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93adecb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        coffee_name  total_sales  total_revenue  avg_price\n",
      "              Latte          757       26875.30      35.50\n",
      "Americano with Milk          809       24751.12      30.59\n",
      "         Cappuccino          486       17439.14      35.88\n",
      "          Americano          564       14650.26      25.98\n",
      "      Hot Chocolate          276        9933.46      35.99\n"
     ]
    }
   ],
   "source": [
    "top_sellers = run_query(\"\"\"\n",
    "SELECT coffee_name, \n",
    "       COUNT(*) AS total_sales, \n",
    "       ROUND(SUM(money), 2) AS total_revenue,\n",
    "       ROUND(AVG(money), 2) AS avg_price\n",
    "FROM coffee_sales\n",
    "GROUP BY coffee_name\n",
    "ORDER BY total_revenue DESC\n",
    "LIMIT 5;\n",
    "\"\"\", conn)\n",
    "\n",
    "print(top_sellers.to_string(index=False)) # to_string to avoid truncation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab496bc0",
   "metadata": {},
   "source": [
    "#### 6.2 Peak Hours\n",
    "\n",
    "- **10 AM is the peak sales hour**, generating $10,198 in revenue. This suggests mornings are the busiest period, likely due to office commuters and the customary \"morning coffee\" routine.\n",
    "\n",
    "- **1–2 PM sees a slight dip** in revenue (~$7,100), which could be an opportunity for **promotions or lunch combos** to boost revenue during this quieter period.\n",
    "\n",
    "- **7 PM–9 PM** ($6,400–$7,700), still generates decent revenue (~$6,398–$7,752), but lower than afternoon. People still buy coffee in the evening; maybe offer **seasonal warm drinks** like Hot Chocolate to increase evening sales.\n",
    "\n",
    "- **6-7 AM** are low hours: $149.40 (6 AM) and $2,846.02 (7 AM). Very early opening may not be worth staffing heavily unless you have loyal early-morning customers. Could **consider reducing staff or offering pre-order options**.\n",
    "\n",
    "**Strategy Recommendations:**\n",
    "- **Staffing**: Allocate more baristas from 9 AM–12 PM and 4 PM–5 PM to handle peak demand.\n",
    "\n",
    "- **Product promotions**: Target slow hours (1–3 PM) with discounts or combos to increase average revenue.\n",
    "\n",
    "- **Menu focus**: Highlight high-margin drinks during peak hours to maximize profits.\n",
    "\n",
    "- **Operational planning**: Monitor inventory for popular drinks during peak hours to avoid shortages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbc761da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hour_of_day  total_revenue  transactions\n",
      "           6         149.40             5\n",
      "           7        2846.02            88\n",
      "           8        7017.88           235\n",
      "           9        7264.28           242\n",
      "          10       10198.52           328\n",
      "          11        8453.10           283\n",
      "          12        7419.62           241\n",
      "          13        7028.76           225\n",
      "          14        7173.80           225\n",
      "          15        7476.02           236\n",
      "          16        9031.84           278\n",
      "          17        7659.76           237\n",
      "          18        7162.60           218\n",
      "          19        7751.96           229\n",
      "          20        5578.92           169\n",
      "          21        6397.94           195\n",
      "          22        3635.16           113\n",
      "\n",
      "Peak Hour: 10:00\n",
      "Peak Revenue: $10,198.52\n"
     ]
    }
   ],
   "source": [
    "peak_hours = run_query(\"\"\"\n",
    "SELECT hour_of_day, \n",
    "       ROUND(SUM(money), 2) AS total_revenue,\n",
    "       COUNT(*) AS transactions\n",
    "FROM coffee_sales\n",
    "GROUP BY hour_of_day\n",
    "ORDER BY hour_of_day;\n",
    "\"\"\", conn)\n",
    "\n",
    "print(peak_hours.to_string(index=False))\n",
    "print(f\"\\nPeak Hour: {peak_hours.loc[peak_hours['total_revenue'].idxmax(), 'hour_of_day']}:00\")\n",
    "print(f\"Peak Revenue: ${peak_hours['total_revenue'].max():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5e48cd",
   "metadata": {},
   "source": [
    "#### 6.3 Revenue by Day of the Week\n",
    "\n",
    "- **Tuesday generates the highest revenue** with $18,168.38, suggesting mid-week demand is strongest.\n",
    "\n",
    "- **Monday** follows closely at $17,363.10, showing strong early-week sales, likely as people start their workweek.\n",
    "\n",
    "- **Friday** brings in $16,802.66, still significant but slightly lower than earlier in the week, which could reflect early weekend patterns.\n",
    "\n",
    "- **Thursday ($16,091.40) and Wednesday ($15,750.46)** show steady mid-week revenue.\n",
    "\n",
    "- **Weekends see lower revenue**: Saturday at $14,733.52 and Sunday at $13,336.06, indicating less foot traffic compared to weekdays.\n",
    "\n",
    "**Strategy Recommendations:**\n",
    "\n",
    "- **Staffing**: Schedule more staff on weekdays, particularly Tuesday and Monday, to handle higher demand.\n",
    "\n",
    "- **Promotions**: Offer weekend promotions to boost sales during slower days.\n",
    "\n",
    "- **Inventory planning**: Ensure top-selling drinks are well-stocked during high-revenue weekdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63801df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekday  total_revenue  transactions  avg_transaction\n",
      "    Mon       17363.10           544            31.92\n",
      "    Tue       18168.38           572            31.76\n",
      "    Wed       15750.46           500            31.50\n",
      "    Thu       16091.40           510            31.55\n",
      "    Fri       16802.66           532            31.58\n",
      "    Sat       14733.52           470            31.35\n",
      "    Sun       13336.06           419            31.83\n"
     ]
    }
   ],
   "source": [
    "revenue_by_day = run_query(\"\"\"\n",
    "SELECT Weekday, \n",
    "       ROUND(SUM(money), 2) AS total_revenue,\n",
    "       COUNT(*) AS transactions,\n",
    "       ROUND(AVG(money), 2) AS avg_transaction\n",
    "FROM coffee_sales\n",
    "GROUP BY Weekday\n",
    "ORDER BY Weekdaysort;\n",
    "\"\"\", conn)\n",
    "\n",
    "print(revenue_by_day.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cce2e7",
   "metadata": {},
   "source": [
    "#### 6.4 Average Sale per Hour\n",
    "\n",
    "- **Morning transactions (6–9 AM)** tend to be smaller, averaging around $29–$32 per sale, reflecting lighter orders early in the day.  \n",
    "\n",
    "- **Late morning to early afternoon (10 AM–2 PM)** sees moderate average sales ($31–$32), coinciding with peak traffic hours.  \n",
    "\n",
    "- **Afternoon and evening (3–9 PM)** have the highest average transaction values, peaking at $33.85 around 7 PM, suggesting customers are purchasing larger or \"premium\" drinks later in the day.  \n",
    "\n",
    "- **Night hours (10–11 PM)** maintain relatively high averages despite fewer customers, indicating that fewer orders are slightly bigger in value.\n",
    "\n",
    "**Strategy Recommendations:**\n",
    "\n",
    "- **Upselling:** Promote premium drinks or add-ons in the afternoon and evening to maximize revenue per transaction.  \n",
    "\n",
    "- **Early morning offers:** Introduce combos or incentives to increase average sales when traffic is lighter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc93a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hour_of_day  avg_sale_per_hour  transactions\n",
      "           6              29.88             5\n",
      "           7              32.34            88\n",
      "           8              29.86           235\n",
      "           9              30.02           242\n",
      "          10              31.09           328\n",
      "          11              29.87           283\n",
      "          12              30.79           241\n",
      "          13              31.24           225\n",
      "          14              31.88           225\n",
      "          15              31.68           236\n",
      "          16              32.49           278\n",
      "          17              32.32           237\n",
      "          18              32.86           218\n",
      "          19              33.85           229\n",
      "          20              33.01           169\n",
      "          21              32.81           195\n",
      "          22              32.17           113\n"
     ]
    }
   ],
   "source": [
    "avg_sale_hour = run_query(\"\"\"\n",
    "SELECT hour_of_day,\n",
    "       ROUND(AVG(money), 2) AS avg_sale_per_hour,\n",
    "       COUNT(*) AS transactions\n",
    "FROM coffee_sales\n",
    "GROUP BY hour_of_day\n",
    "ORDER BY hour_of_day;\n",
    "\"\"\", conn)\n",
    "\n",
    "print(avg_sale_hour.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a92a8",
   "metadata": {},
   "source": [
    "#### 6.5 Monthly Sales Performance: Growth Rate by Month\n",
    "\n",
    "- **Stable start**: Mar–Apr stay steady, with only a slight dip (–3%).\n",
    "\n",
    "- **Spring lift**: May rises sharply (+43%), the first strong upward shift.\n",
    "\n",
    "- **Summer softness**: Jun–Jul decline (–7% to –9%), signaling weaker mid-year performance.\n",
    "\n",
    "- **Late-summer recovery**: Aug rebounds (+10%) after July’s drop.\n",
    "\n",
    "- **Peak season**: Sep–Oct deliver the strongest growth (+31% and +39%).\n",
    "\n",
    "- **Sharp correction**: Nov plunges (–38%), the steepest fall in the cycle.\n",
    "\n",
    "- **Year-end steadiness**: Dec slips only –4%, holding more stable than November.\n",
    "\n",
    "- **Post-holiday slump**: Jan 2025 drops –22%, typical for early-year slowdowns.\n",
    "\n",
    "- **Major rebound**: Feb 2025 surges (+107%), doubling revenue.\n",
    "\n",
    "- **Spring adjustment**: Mar 2025 falls –24%, normalizing after February’s spike.\n",
    "\n",
    "**Strategy Recommendations**:\n",
    "- Prioritize staffing and inventory for Sep–Oct, when demand peaks.\n",
    "- Use May and Feb surges to introduce new drinks or limited-time offers.\n",
    "- Create targeted promotions or loyalty incentives during weak periods (Jun–Jul, Nov, Jan).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82741bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Period    Revenue  Transactions Growth Rate\n",
      "Mar 2024  $5,905.20           175       0.00%\n",
      "Apr 2024  $5,719.56           168      -3.14%\n",
      "May 2024  $8,164.42           241      42.75%\n",
      "Jun 2024  $7,617.76           223      -6.70%\n",
      "Jul 2024  $6,915.94           237      -9.21%\n",
      "Aug 2024  $7,613.84           272      10.09%\n",
      "Sep 2024  $9,988.64           344      31.19%\n",
      "Oct 2024 $13,891.16           426      39.07%\n",
      "Nov 2024  $8,590.54           259     -38.16%\n",
      "Dec 2024  $8,237.74           259      -4.11%\n",
      "Jan 2025  $6,398.86           201     -22.32%\n",
      "Feb 2025 $13,215.48           423     106.53%\n",
      "Mar 2025  $9,986.44           319     -24.43%\n"
     ]
    }
   ],
   "source": [
    "# Use month_sequence for proper ordering\n",
    "monthly_sales = df.groupby(['year_month_display', 'month_sequence', 'year_month_sort'])['money'].agg([\n",
    "    ('total_revenue', 'sum'),\n",
    "    ('transactions', 'count'),\n",
    "    ('avg_transaction', 'mean')\n",
    "]).reset_index()\n",
    "monthly_sales = monthly_sales.sort_values('month_sequence')\n",
    "\n",
    "# Calculate growth rate\n",
    "monthly_sales['growth_rate'] = (\n",
    "    monthly_sales['total_revenue'].pct_change().fillna(0) * 100\n",
    ").round(2)\n",
    "\n",
    "# Display with proper labels\n",
    "monthly_display = monthly_sales[['year_month_display', 'total_revenue', 'transactions', 'growth_rate']].copy()\n",
    "monthly_display['total_revenue'] = monthly_display['total_revenue'].apply(lambda x: f\"${x:,.2f}\")\n",
    "monthly_display['growth_rate'] = monthly_display['growth_rate'].apply(lambda x: f\"{x:.2f}%\")\n",
    "monthly_display.columns = ['Period', 'Revenue', 'Transactions', 'Growth Rate']\n",
    "print(monthly_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b064943e",
   "metadata": {},
   "source": [
    "#### 6.6 Sales by Time of Day\n",
    "\n",
    "- **Morning**: 1,181 transactions generating $35,929, with an average ticket of $30.42 — steady but slightly lower-value sales.\n",
    "\n",
    "- **Afternoon**: 1,205 transactions and $38,130 in revenue, driven by a higher average value ($31.64).\n",
    "\n",
    "- **Night**: 1,161 transactions producing $38,186, the highest average ticket ($32.89), indicating stronger spending later in the day.\n",
    "\n",
    "**Strategy Recommendations**:\n",
    "\n",
    "- Promote breakfast combos or loyalty perks in the morning to lift the lower average ticket.\n",
    "\n",
    "- Capitalize on strong afternoon traffic with targeted upsells (iced drinks, add-ons).\n",
    "\n",
    "- Leverage high-value night purchases with premium drinks or limited evening specials to maximize spending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa3bc927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time_of_Day  transactions  total_revenue  avg_transaction\n",
      "    Morning          1181       35929.20            30.42\n",
      "  Afternoon          1205       38130.04            31.64\n",
      "      Night          1161       38186.34            32.89\n"
     ]
    }
   ],
   "source": [
    "time_of_day_analysis = run_query(\"\"\"\n",
    "SELECT Time_of_Day,\n",
    "       COUNT(*) AS transactions,\n",
    "       ROUND(SUM(money), 2) AS total_revenue,\n",
    "       ROUND(AVG(money), 2) AS avg_transaction\n",
    "FROM coffee_sales\n",
    "GROUP BY Time_of_Day\n",
    "ORDER BY \n",
    "    CASE Time_of_Day\n",
    "        WHEN 'Morning' THEN 1\n",
    "        WHEN 'Afternoon' THEN 2\n",
    "        WHEN 'Night' THEN 3\n",
    "    END;\n",
    "\"\"\", conn)\n",
    "\n",
    "print(time_of_day_analysis.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01345b08",
   "metadata": {},
   "source": [
    "### 7. Outliers: Extreme Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e2f28d",
   "metadata": {},
   "source": [
    "#### 7.1 Overview\n",
    "\n",
    "- Transaction count: 1,415 purchases exceed the high-value threshold, representing the top tier of sales.\n",
    "\n",
    "- Revenue impact: These transactions generate $51,511.80, accounting for 46% of total revenue, highlighting their outsized contribution.\n",
    "\n",
    "- Average value: Each high-value transaction averages $36.40, slightly above typical sales, confirming that larger purchases are common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "553c7906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric      Value\n",
      "High-value transactions      1,415\n",
      "          Total revenue $51,511.80\n",
      "          Average value     $36.40\n",
      "     % of total revenue     45.89%\n",
      "        Threshold value     $35.76\n"
     ]
    }
   ],
   "source": [
    "# Threshold for top 25% transactions\n",
    "threshold = df['money'].quantile(0.75)\n",
    "high_value_sales = df[df['money'] >= threshold]\n",
    "\n",
    "# Summary statistics for high-value transactions\n",
    "num_outliers = len(high_value_sales)\n",
    "total_outliers = high_value_sales['money'].sum()\n",
    "avg_outliers = high_value_sales['money'].mean()\n",
    "pct_of_total = total_outliers / df['money'].sum() * 100\n",
    "\n",
    "# Display summary\n",
    "summary = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"High-value transactions\", \n",
    "        \"Total revenue\", \n",
    "        \"Average value\", \n",
    "        \"% of total revenue\",\n",
    "        \"Threshold value\"\n",
    "    ], \n",
    "    \"Value\": [\n",
    "        f\"{num_outliers:,}\",\n",
    "        f\"${total_outliers:,.2f}\", \n",
    "        f\"${avg_outliers:.2f}\", \n",
    "        f\"{pct_of_total:.2f}%\",\n",
    "        f\"${threshold:.2f}\"\n",
    "    ]\n",
    "})\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87753fba",
   "metadata": {},
   "source": [
    "#### 7.2 High-Value Coffee Transactions: Item Contribution to Top Sales\n",
    "\n",
    "- **Top contributor**: Latte dominates high-value sales, generating $20,508 (40% of total), with 563 transactions averaging $36.43 each.\n",
    "\n",
    "\n",
    "- **Strong performers**: Cappuccino follows with $14,288 (28%), 390 transactions, and a similar average transaction value ($36.64).\n",
    "\n",
    "\n",
    "- **Mid-tier contributors**: Hot Chocolate brings in $9,080 (18%) across 250 transactions, slightly below the top two in both revenue and count.\n",
    "\n",
    "\n",
    "- **Smaller but notable**: Cocoa adds $7,635 (15%) from 212 transactions, maintaining consistent average value ($36.01).\n",
    "\n",
    "\n",
    "**Strategy Recommendations**: \n",
    "- Upselling or promotions targeting Lattes and Cappuccinos could maximize revenue, while Hot Chocolate and Cocoa represent steady secondary options for high-value sales.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82f4c541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total_revenue  transaction_count avg_value  \\\n",
      "coffee_name                                                \n",
      "Latte            $20,508.22                563    $36.43   \n",
      "Cappuccino       $14,288.42                390    $36.64   \n",
      "Hot Chocolate     $9,080.14                250    $36.32   \n",
      "Cocoa             $7,635.02                212    $36.01   \n",
      "\n",
      "              pct_of_high_value_revenue  \n",
      "coffee_name                              \n",
      "Latte                            39.81%  \n",
      "Cappuccino                       27.74%  \n",
      "Hot Chocolate                    17.63%  \n",
      "Cocoa                            14.82%  \n"
     ]
    }
   ],
   "source": [
    "# Aggregate high-value sales by coffee item\n",
    "coffee_high_value = high_value_sales.groupby('coffee_name').agg(\n",
    "    total_revenue=('money', 'sum'), # total revenue from high-value sales\n",
    "    transaction_count=('money', 'count'), # number of high-value transactions\n",
    "    avg_value=('money', 'mean') # average value of high-value transactions\n",
    ").sort_values(by='total_revenue', ascending=False)\n",
    "\n",
    "# Calculate percentage of high-value revenue for each coffee item\n",
    "coffee_high_value['pct_of_high_value_revenue'] = (\n",
    "    coffee_high_value['total_revenue'] / high_value_sales['money'].sum() * 100\n",
    ").round(2)\n",
    "\n",
    "# Format monetary values and percentages for display\n",
    "coffee_high_value['total_revenue'] = coffee_high_value['total_revenue'].apply(lambda x: f\"${x:,.2f}\")\n",
    "coffee_high_value['avg_value'] = coffee_high_value['avg_value'].apply(lambda x: f\"${x:.2f}\")\n",
    "coffee_high_value['pct_of_high_value_revenue'] = coffee_high_value['pct_of_high_value_revenue'].apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "print(coffee_high_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6e3d3",
   "metadata": {},
   "source": [
    "### 8. Predictive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13480053",
   "metadata": {},
   "source": [
    "#### 8.1 Hourly Sales Forecast (6:00 - 22:00)\n",
    "Predicting expected revenue for each hour of the day using polynomial regression to capture peak and off-peak trends.\n",
    "\n",
    "- **Peak sales** expected between 16:00–22:00, with predicted revenue gradually increasing throughout the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10febb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hour predicted_avg_transaction\n",
      " 6:00                    $30.16\n",
      " 7:00                    $30.34\n",
      " 8:00                    $30.52\n",
      " 9:00                    $30.70\n",
      "10:00                    $30.89\n",
      "11:00                    $31.07\n",
      "12:00                    $31.26\n",
      "13:00                    $31.45\n",
      "14:00                    $31.64\n",
      "15:00                    $31.83\n",
      "16:00                    $32.02\n",
      "17:00                    $32.22\n",
      "18:00                    $32.41\n",
      "19:00                    $32.61\n",
      "20:00                    $32.81\n",
      "21:00                    $33.02\n",
      "22:00                    $33.22\n"
     ]
    }
   ],
   "source": [
    "# Aggregate average sales by hour\n",
    "hourly_sales = df.groupby('hour_of_day')['money'].mean().reset_index()\n",
    "X = hourly_sales[['hour_of_day']]\n",
    "y = hourly_sales['money']\n",
    "\n",
    "# Polynomial regression model (degree 2), for capturing peak/off-peak trends\n",
    "poly_hour_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "poly_hour_model.fit(X, y)\n",
    "\n",
    "# Predict average sales for each hour from 6:00 to 22:00\n",
    "future_hours = pd.DataFrame({'hour_of_day': range(6, 23)})\n",
    "predicted_hourly_sales = poly_hour_model.predict(future_hours)\n",
    "\n",
    "# Format and display predictions\n",
    "predicted_hourly_sales_df = future_hours.copy()\n",
    "predicted_hourly_sales_df['predicted_avg_transaction'] = predicted_hourly_sales\n",
    "predicted_hourly_sales_df['predicted_avg_transaction'] = predicted_hourly_sales_df['predicted_avg_transaction'].apply(\n",
    "    lambda x: f\"${x:.2f}\"\n",
    ")\n",
    "predicted_hourly_sales_df['hour'] = predicted_hourly_sales_df['hour_of_day'].apply(lambda x: f\"{x}:00\")\n",
    "print(predicted_hourly_sales_df[['hour', 'predicted_avg_transaction']].to_string(index=False))\n",
    "\n",
    "# Note: I used polynomial regression with degree 2 because the hourly sales data showed a curved pattern - sales rise during morning rush, plateau midday, and change throughout the evening. A simple linear model couldn't capture this non-linear relationship, while degree 2 provided the right amount of curvature without overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b14649",
   "metadata": {},
   "source": [
    "#### 8.2 Monthly Sales Forecast (Next 3 Months)\n",
    "Predicting expected monthly revenue based on historical trends using polynomial regression, including simulated next months.\n",
    "\n",
    "- Revenue is projected to **increase gradually**, reaching ~$11,076 in March."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb207168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Period Predicted Revenue  Month Sequence\n",
      "May 2025        $10,021.35              14\n",
      "Jun 2025         $9,886.23              15\n",
      "Jul 2025         $9,684.47              16\n"
     ]
    }
   ],
   "source": [
    "# Use month_sequence for proper temporal ordering\n",
    "monthly_sales_seq = df.groupby('month_sequence')['money'].sum().reset_index()\n",
    "monthly_sales_seq = monthly_sales_seq.sort_values('month_sequence')\n",
    "\n",
    "# Polynomial regression model (degree 2) for monthly sales trend, capturing non-linear growth\n",
    "X_month = monthly_sales_seq[['month_sequence']]\n",
    "y_month = monthly_sales_seq['money']\n",
    "\n",
    "poly_month_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "poly_month_model.fit(X_month, y_month)\n",
    "\n",
    "# Predict next 3 months after the last month in your data\n",
    "max_month = df['month_sequence'].max()\n",
    "future_months = pd.DataFrame({'month_sequence': [max_month + 1, max_month + 2, max_month + 3]})\n",
    "predicted_monthly_sales = poly_month_model.predict(future_months)\n",
    "\n",
    "# Create readable labels based on your last date\n",
    "last_date = df['Date'].max()\n",
    "future_dates = pd.date_range(start=last_date + pd.DateOffset(months=1), periods=3, freq='MS')\n",
    "\n",
    "# Format and display predictions\n",
    "predicted_monthly_sales_df = pd.DataFrame({\n",
    "    'Period': future_dates.strftime('%b %Y'),\n",
    "    'Predicted Revenue': [f\"${x:,.2f}\" for x in predicted_monthly_sales],\n",
    "    'Month Sequence': [max_month + 1, max_month + 2, max_month + 3]\n",
    "})\n",
    "print(predicted_monthly_sales_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d0373",
   "metadata": {},
   "source": [
    "### 9. Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26556280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Period: Mar 2024 to Mar 2025\n",
      "Total Duration: 13 months\n",
      "Date Range: 2024-03-01 to 2025-03-23\n",
      "\n",
      "Total Transactions: 3,547\n",
      "Total Revenue: $112,245.58\n",
      "Average Transaction: $31.65\n",
      "Unique Products: 8\n",
      "\n",
      "Peak Hour: 10:00 ($10,198.52)\n",
      "Best Day: Tue ($18,168.38)\n",
      "Top Product: Latte ($26,875.30 revenue)\n"
     ]
    }
   ],
   "source": [
    "# Get date range information\n",
    "first_month = df.loc[df['Date'].idxmin(), 'year_month_display']\n",
    "last_month = df.loc[df['Date'].idxmax(), 'year_month_display']\n",
    "\n",
    "# Calculate summary statistics\n",
    "total_revenue = df['money'].sum()\n",
    "total_transactions = len(df)\n",
    "avg_transaction = df['money'].mean()\n",
    "unique_products = df['coffee_name'].nunique()\n",
    "\n",
    "# Display summary\n",
    "print(f\"Analysis Period: {first_month} to {last_month}\")\n",
    "print(f\"Total Duration: {df['month_sequence'].nunique()} months\")\n",
    "print(f\"Date Range: {df['Date'].min().date()} to {df['Date'].max().date()}\")\n",
    "print(f\"\\nTotal Transactions: {total_transactions:,}\")\n",
    "print(f\"Total Revenue: ${total_revenue:,.2f}\")\n",
    "print(f\"Average Transaction: ${avg_transaction:.2f}\")\n",
    "print(f\"Unique Products: {unique_products}\")\n",
    "print(f\"\\nPeak Hour: {peak_hours.loc[peak_hours['total_revenue'].idxmax(), 'hour_of_day']}:00 (${peak_hours['total_revenue'].max():,.2f})\")\n",
    "print(f\"Best Day: {revenue_by_day.loc[revenue_by_day['total_revenue'].idxmax(), 'Weekday']} (${revenue_by_day['total_revenue'].max():,.2f})\")\n",
    "print(f\"Top Product: {top_sellers.iloc[0]['coffee_name']} (${top_sellers.iloc[0]['total_revenue']:,.2f} revenue)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce10935",
   "metadata": {},
   "source": [
    "### 10. Close the Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (biodiversity)",
   "language": "python",
   "name": "biodiversity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
